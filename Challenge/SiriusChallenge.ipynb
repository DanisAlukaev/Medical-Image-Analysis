{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Sirius_Challenge 64.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"T9CUFr9Ljo8L"},"source":["# Move the dataset to VM."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"es2OgUwz_Fl6","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"a4aff09e-7de7-4b5c-f9e8-39a3dc488caa"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AUlQCBIZKLPJ"},"source":["### Create directories"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UlcMtaeZPo0B","colab":{}},"source":["mkdir train_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Z5CnQwk_QFKI","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ba812043-fda2-4e28-8763-22bbb4ed0cbd"},"source":["cd train_data"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/train_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ullBkGzuQLdK","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ba896e90-cb96-42fd-f2ac-ad37000345a6"},"source":["mkdir lateral"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘lateral’: File exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ztZ5D5zTQbOQ","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b9ff8d46-7efd-45d2-c3f8-e15b70eae423"},"source":["mkdir frontal"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘frontal’: File exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3Ft9WbGJ0BdJ","colab":{}},"source":["ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7ejTlwEF0G_o","colab":{}},"source":["mkdir test_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rIAYAHCCkmxp","colab":{}},"source":["import csv\n","from shutil import copyfile\n","import os\n","import zipfile"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5wWmq0UOU7ul","colab":{}},"source":["# copy all images in train folder\n","csvReader = csv.DictReader(open(\"/content/drive/My Drive/Sirius challenge/train_new.csv\"))\n","for row in csvReader:\n","    if row['label'] == 'frontal':\n","      dst = '/content/train_data/frontal/' + row['target_name']\n","    elif row['label'] == 'lateral':\n","      dst = '/content/train_data/lateral/' + row['target_name']\n","    copyfile('/content/drive/My Drive/Sirius challenge/chexpertData_new/' + row['target_name'], dst)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"swu49-Zyzrr1","colab":{}},"source":["# copy all images in test folder\n","csvReader = csv.DictReader(open(\"/content/drive/My Drive/Sirius challenge/test_new.csv\"))\n","for row in csvReader:\n","    dst = '/content/test_data/' + row['target_name']\n","    copyfile('/content/drive/My Drive/Sirius challenge/chexpertData_new/' + row['target_name'], dst)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YM0LaXObKFoK"},"source":["### Zip"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"v8FJuQ37hAq2","colab":{}},"source":["# zip both folders\n","# then we can upload them in google drive and do not repeat all these actions\n","\n","def zipdir(path, ziph):\n","    for root, dirs, files in os.walk(path):\n","        for file in files:\n","            ziph.write(os.path.join(root, file))\n","\n","zipf = zipfile.ZipFile('/content/train_data.zip', 'w', zipfile.ZIP_DEFLATED)\n","zipdir('/content/train_data', zipf)\n","zipf.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lqT_gL5l1myu","colab":{}},"source":["zipf = zipfile.ZipFile('/content/test_data.zip', 'w', zipfile.ZIP_DEFLATED)\n","zipdir('/content/test_data', zipf)\n","zipf.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0wrIhM3ZKBkp","colab":{}},"source":["zipf = zipfile.ZipFile('/content/GB7.zip', 'w', zipfile.ZIP_DEFLATED)\n","zipdir('/content/drive/My Drive/Sirius challenge/GB7_new', zipf)\n","zipf.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XMAQiqpwJ1S9"},"source":["### Unzip\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NWibS3ge6UQA","colab":{}},"source":["# unzip GB7 dataset\n","with zipfile.ZipFile('/content/drive/My Drive/GB7.zip', 'r') as zip_ref:\n","    zip_ref.extractall('')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0Oe9KAwshUyB","colab":{}},"source":["# unzip train dataset\n","with zipfile.ZipFile('/content/drive/My Drive/train_data.zip', 'r') as zip_ref:\n","    zip_ref.extractall('')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"v5ouNz0VC86s","colab":{}},"source":["# unzip test dataset\n","with zipfile.ZipFile('/content/drive/My Drive/test_data.zip', 'r') as zip_ref:\n","    zip_ref.extractall('')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"a-oF9Jvm9AHg"},"source":["# Main code\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tyNsXd-6bNuL","colab":{}},"source":["import torch\n","import numpy as np\n","from torchvision import datasets\n","import torchvision.transforms as transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import cv2\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import csv\n","from PIL import Image\n","import numpy \n","from shutil import copyfile\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ruYrkYXzR1Z-"},"source":["### Increase training images \n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7m74dCJoS_Mc","colab":{"base_uri":"https://localhost:8080/","height":530},"outputId":"39552ef2-454d-450d-ab5a-f272098c98ee"},"source":["!pip install albumentations"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: albumentations in /usr/local/lib/python3.6/dist-packages (0.1.12)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from albumentations) (4.1.2.30)\n","Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.18.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.4.1)\n","Collecting imgaug<0.2.7,>=0.2.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n","\u001b[K     |████████████████████████████████| 634kB 4.6MB/s \n","\u001b[?25hRequirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (0.16.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (1.15.0)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.1.1)\n","Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (7.0.0)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.2.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (4.4.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.7)\n","Building wheels for collected packages: imgaug\n","  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=654020 sha256=78f05aa96f6af757d3401c947cbe04db46f7a002b8f596c432fb2adc6d4dcdb3\n","  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n","Successfully built imgaug\n","Installing collected packages: imgaug\n","  Found existing installation: imgaug 0.2.9\n","    Uninstalling imgaug-0.2.9:\n","      Successfully uninstalled imgaug-0.2.9\n","Successfully installed imgaug-0.2.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"f2F_3GWdR0w9","colab":{}},"source":["import albumentations as A\n","\n","augmentation = A.Compose([\n","        A.RandomRotate90(p=0.4),\n","        A.Flip(p=0.4),\n","        A.OneOf([\n","            A.IAAAdditiveGaussianNoise(),\n","            A.GaussNoise(),\n","        ], p=0.4),\n","    ], p=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"r0buFzlhSvEJ","colab":{}},"source":["for root, dirs, files in os.walk('/content/train_data/', topdown=True):\n","    for name in files:\n","      if random.random() > 0.99:\n","        img = cv2.imread(os.path.abspath(os.path.join(root, name)),0)\n","        new = augmentation(image = img)['image']\n","        components = os.path.abspath(os.path.join(root, 'a_'+name)).split('/')\n","        path = os.path.abspath(os.path.join(root, components[-1]))\n","        cv2.imwrite(path, new)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yuVwvBgENW8D"},"source":["### Set hyperparameters"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QANPPn0Ab-gk","colab":{}},"source":["batch_size = 64\n","test_size = 0\n","valid_size = 0.1\n","\n","transform = transforms.Compose([\n","    transforms.Resize(size=(64,64)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","    ])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cRH4sVPpc_cf","colab":{"base_uri":"https://localhost:8080/","height":170},"outputId":"e34cdcc9-cae2-48bf-d7e8-e57fa00959ad"},"source":["data = datasets.ImageFolder('/content/train_data', transform=transform)\n","data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset ImageFolder\n","    Number of datapoints: 3199\n","    Root location: /content/train_data\n","    StandardTransform\n","Transform: Compose(\n","               Resize(size=(64, 64), interpolation=PIL.Image.BILINEAR)\n","               ToTensor()\n","               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n","           )"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oKdHYBkfbwYN","colab":{}},"source":["num_data = len(data)\n","indices_data = list(range(num_data))\n","np.random.shuffle(indices_data)\n","split_tt = int(np.floor(test_size * num_data))\n","train_idx, test_idx = indices_data[split_tt:], indices_data[:split_tt]\n","\n","num_train = len(train_idx)\n","indices_train = list(range(num_train))\n","np.random.shuffle(indices_train)\n","split_tv = int(np.floor(valid_size * num_train))\n","train_new_idx, valid_idx = indices_train[split_tv:],indices_train[:split_tv]\n","\n","train_sampler = SubsetRandomSampler(train_new_idx)\n","test_sampler = SubsetRandomSampler(test_idx)\n","valid_sampler = SubsetRandomSampler(valid_idx)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"seXckTmib84B","colab":{}},"source":["train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size,\n","    sampler=train_sampler, num_workers=1)\n","valid_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, \n","    sampler=valid_sampler, num_workers=1)\n","test_loader = torch.utils.data.DataLoader(data, sampler = test_sampler, batch_size=batch_size, \n","    num_workers=1)\n","classes = [1,0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1EL7dahgb9zk","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"7d1b3620-01fd-4744-c499-b0ab24eea135"},"source":["len(test_loader)*batch_size + len(valid_loader)*batch_size + len(train_loader)*batch_size"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3200"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ohw_Zl2yccPc","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"30fdeae7-a3fd-49be-86c6-f3f3983ba2cf"},"source":["# define neural net architecture\n","train_on_gpu = torch.cuda.is_available()\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, 3)\n","        self.conv2 = nn.Conv2d(16, 64, 3)\n","        self.fc1 = nn.Linear(64*14*14, 512)\n","        self.fc2 = nn.Linear(512, 80)\n","        self.fc3 = nn.Linear(80, 1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.dropout = nn.Dropout(0.2)\n","        self.sig = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = self.pool(self.conv1(x))\n","        x = self.pool(F.elu(self.conv2(x)))\n","        x = x.view(-1, 64*14*14)\n","        x = F.elu(self.fc1(x))\n","        x = F.elu(self.fc2(x))\n","        x = self.dropout(x)\n","        x = self.fc3(x)\n","        x = self.sig(x)\n","        return x\n","\n","model = Net()\n","print(model)\n","\n","if train_on_gpu:\n","    model.cuda()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Net(\n","  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n","  (conv2): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (fc1): Linear(in_features=12544, out_features=512, bias=True)\n","  (fc2): Linear(in_features=512, out_features=80, bias=True)\n","  (fc3): Linear(in_features=80, out_features=1, bias=True)\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (dropout): Dropout(p=0.2, inplace=False)\n","  (sig): Sigmoid()\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dM-bps3zciK-","colab":{}},"source":["# set loss function and optimization algorithm\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4HHWnk14ckia","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"ec3caa40-1a31-4835-fa02-81709ab7c5ef"},"source":["# training loop\n","n_epochs = 7 \n","valid_loss_min = np.Inf \n","t2vRatio = 1.9           \n","t2vEpochs = 2   \n","\n","for epoch in range(1, n_epochs+1):\n","    train_loss = 0.0\n","    valid_loss = 0.0\n","    model.train()\n","    for data, target in train_loader:\n","        if train_on_gpu:\n","            data, target = data.cuda(), target.cuda()\n","        optimizer.zero_grad()\n","        output = model(data).squeeze(1)\n","        # print(output.cpu(), target.cpu())\n","        loss = criterion(output, target.type_as(output))\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()*data.size(0)\n","    model.eval()\n","    for data, target in valid_loader:\n","        if train_on_gpu:\n","            data, target = data.cuda(), target.cuda()\n","        output = model(data).squeeze(1)\n","        loss = criterion(output, target.type_as(output))\n","        valid_loss += loss.item()*data.size(0)\n","    train_loss = train_loss/len(train_loader.dataset)\n","    valid_loss = valid_loss/len(valid_loader.dataset)\n","    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))\n","    if valid_loss <= valid_loss_min:\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n","        torch.save(model.state_dict(), 'challenge.pth')\n","        valid_loss_min = valid_loss\n","    if valid_loss > t2vRatio * valid_loss:\n","      t2vEpochs -= 1                \n","      if t2vEpochs < 1:\n","        print(\"Validation loss too high; halting to prevent overfitting\")\n","        break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: 1 \tTraining Loss: 0.102551 \tValidation Loss: 0.001761\n","Validation loss decreased (inf --> 0.001761).  Saving model ...\n","Epoch: 2 \tTraining Loss: 0.032721 \tValidation Loss: 0.001128\n","Validation loss decreased (0.001761 --> 0.001128).  Saving model ...\n","Epoch: 3 \tTraining Loss: 0.015349 \tValidation Loss: 0.000196\n","Validation loss decreased (0.001128 --> 0.000196).  Saving model ...\n","Epoch: 4 \tTraining Loss: 0.007456 \tValidation Loss: 0.000401\n","Epoch: 5 \tTraining Loss: 0.004847 \tValidation Loss: 0.000064\n","Validation loss decreased (0.000196 --> 0.000064).  Saving model ...\n","Epoch: 6 \tTraining Loss: 0.013878 \tValidation Loss: 0.000586\n","Epoch: 7 \tTraining Loss: 0.001417 \tValidation Loss: 0.000010\n","Validation loss decreased (0.000064 --> 0.000010).  Saving model ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Evur3pyNd37Z","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"cd17ef98-79b2-4643-c552-14a2a4c24258"},"source":["# create file predictions.csv to store the predictions\n","copyfile('/content/drive/My Drive/sample_subm_1.csv', '/content/result.csv')\n","# evaluate trained model\n","model.eval()\n","correct = 0\n","with open('/content/drive/My Drive/sample_subm_1.csv','r') as csvinput:\n","    # we use the random.csv template\n","    with open('/content/result.csv', 'w') as csvoutput:\n","        writer = csv.writer(csvoutput)\n","        for row in csv.reader(csvinput):\n","            if row[0] != 'target_name':\n","                if row[0][:7] == 'patient':\n","                  # the body of the table\n","                  img = cv2.imread('/content/test_data/'+row[0],0)\n","                else:\n","                  img = cv2.imread('/content/drive/My Drive/Sirius challenge/GB7_new/'+row[0],0)\n","                  img = np.invert(img)\n","                \n","                \n","                if len(np.shape(img)) == 2:\n","                  img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n","                # use the same transformation as it was in training\n","                transform = transforms.Compose([\n","                  transforms.Resize(size=(64, 64)),\n","                  transforms.ToTensor(),\n","                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","                ])\n","                img = transform(Image.fromarray(img)).cuda()\n","                with torch.no_grad() as tn:\n","                  # get the prediction\n","                  output = model(img[None, ...])\n","                  # set number representation\n","                  res = '{:.6f}'.format(1-output.cpu().numpy()[0][0])\n","                  writer.writerow([row[0]]+[res])\n","            \n","                # just to observe the improvement in the classification after code changes\n","                if float(res) > 0.5 and row[0][-9:] == 'view1.png':\n","                  correct += 1\n","                elif float(res) <= 0.5 and (row[0][-9:] == 'view2.png' or row[0][-9:] == 'view3.png'):\n","                  correct += 1\n","                # the following images are incorrectly named so we will process them separately\n","                elif row[0] == 'patient05974study4view1.png' and float(res) <= 0.5:\n","                  correct +=1\n","                elif row[0] == 'patient00942study4view2.png' and float(res) > 0.5:\n","                  correct +=1\n","                elif row[0] == 'patient01645study8view2.png' and float(res) > 0.5:\n","                  correct +=1\n","                elif row[0] == 'patient00204study7view2.png' and float(res) > 0.5:\n","                  correct +=1\n","                elif row[0] == 'patient01489study15view2.png' and float(res) > 0.5:\n","                  correct +=1\n","                elif row[0] == 'patient03368study1view2.png' and float(res) > 0.5:\n","                  correct +=1\n","                # prediction errors\n","                elif row[0][:7] == 'patient': \n","                  print(row[0], ' ', res)\n","            else:\n","                # the header of the table\n","                writer.writerow([row[0]]+[row[1]]) \n","print(\"Final accuracy {:-4}/800\".format(correct))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Final accuracy  800/800\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7jDNbnRnYwUz","colab":{}},"source":["torch.save(model.state_dict(), 'challenge.pth')"],"execution_count":null,"outputs":[]}]}